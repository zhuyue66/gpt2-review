{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 加载预训练模型，生成语音"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[28065,    11,   257,   582,  3706,  3619,   531,   339,  2497,   281,\n          8756,    11]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# 载入预训练模型的分词器\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# 使用 GPT2Tokenizer 对输入进行编码\n",
    "text = \"Yesterday, a man named Jack said he saw an alien,\"\n",
    "indexed_tokens = tokenizer.encode(text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "tokens_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_top_k(predictions, k=10):\n",
    "    predicted_index = random.choice(\n",
    "        predictions[0, -1, :].sort(descending=True)[1][:10]).item()\n",
    "    return predicted_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/envs/hug-trans/lib/python3.8/site-packages/IPython/core/async_helpers.py:129\u001B[0m, in \u001B[0;36m_pseudo_sync_runner\u001B[0;34m(coro)\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;124;03mA runner that does not really allow async execution, and just advance the coroutine.\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;124;03mCredit to Nathaniel Smith\u001B[39;00m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 129\u001B[0m     \u001B[43mcoro\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mvalue\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/hug-trans/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3139\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_async\u001B[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001B[0m\n\u001B[1;32m   3135\u001B[0m has_raised \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_ast_nodes(code_ast\u001B[38;5;241m.\u001B[39mbody, cell_name,\n\u001B[1;32m   3136\u001B[0m        interactivity\u001B[38;5;241m=\u001B[39minteractivity, compiler\u001B[38;5;241m=\u001B[39mcompiler, result\u001B[38;5;241m=\u001B[39mresult)\n\u001B[1;32m   3138\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_execution_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m has_raised\n\u001B[0;32m-> 3139\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_execution_result \u001B[38;5;241m=\u001B[39m result\n\u001B[1;32m   3141\u001B[0m \u001B[38;5;66;03m# Reset this so later displayed values do not modify the\u001B[39;00m\n\u001B[1;32m   3142\u001B[0m \u001B[38;5;66;03m# ExecutionResult\u001B[39;00m\n\u001B[1;32m   3143\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisplayhook\u001B[38;5;241m.\u001B[39mexec_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/hug-trans/lib/python3.8/site-packages/traitlets/traitlets.py:606\u001B[0m, in \u001B[0;36mTraitType.__set__\u001B[0;34m(self, obj, value)\u001B[0m\n\u001B[1;32m    604\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m TraitError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m trait is read-only.\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 606\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/hug-trans/lib/python3.8/site-packages/traitlets/traitlets.py:595\u001B[0m, in \u001B[0;36mTraitType.set\u001B[0;34m(self, obj, value)\u001B[0m\n\u001B[1;32m    591\u001B[0m     silent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    592\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m silent \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    593\u001B[0m     \u001B[38;5;66;03m# we explicitly compare silent to True just in case the equality\u001B[39;00m\n\u001B[1;32m    594\u001B[0m     \u001B[38;5;66;03m# comparison above returns something other than True/False\u001B[39;00m\n\u001B[0;32m--> 595\u001B[0m     \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_notify_trait\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mold_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_value\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/hug-trans/lib/python3.8/site-packages/traitlets/traitlets.py:1219\u001B[0m, in \u001B[0;36mHasTraits._notify_trait\u001B[0;34m(self, name, old_value, new_value)\u001B[0m\n\u001B[1;32m   1218\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_notify_trait\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, old_value, new_value):\n\u001B[0;32m-> 1219\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnotify_change(\u001B[43mBunch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1220\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mold_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnew\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mowner\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mchange\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "# 读取 GPT-2 预训练模型\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "total_predicted_text = text\n",
    "n = 100  # 预测过程的循环次数\n",
    "for _ in range(n):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "    predicted_index = select_top_k(predictions, k=10)\n",
    "    predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
    "    total_predicted_text += tokenizer.decode(predicted_index)\n",
    "\n",
    "    if '<|endoftext|>' in total_predicted_text:\n",
    "        # 如果出现文本结束标志，就结束文本生成\n",
    "        break\n",
    "\n",
    "    indexed_tokens += [predicted_index]\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "print(total_predicted_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finetune to drama\n",
    "## load dataset and encode the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "138150"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 31\n"
     ]
    }
   ],
   "source": [
    "with open('./data/romeo_and_juliet.txt', 'r') as f:\n",
    "    dataset = f.read()\n",
    "\n",
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([81, 512])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_text = tokenizer.encode(dataset)\n",
    "del(dataset)\n",
    "\n",
    "dataset_cut = []\n",
    "for i in range(len(indexed_text)//512):\n",
    "    # 将字符串分段成长度为 512\n",
    "    dataset_cut.append(indexed_text[i*512:i*512+512])\n",
    "del(indexed_text)\n",
    "\n",
    "dataset_tensor = torch.tensor(dataset_cut)\n",
    "dataset_tensor.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x7ff96f403df0>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 构建数据集和数据迭代器，设定 batch_size 大小为 2\n",
    "train_set = TensorDataset(dataset_tensor,\n",
    "                          dataset_tensor)  # 标签与样本数据相同\n",
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=2,\n",
    "                          shuffle=False)\n",
    "train_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [54]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m result \u001B[38;5;241m=\u001B[39m model(data, labels\u001B[38;5;241m=\u001B[39mtarget)\n\u001B[1;32m     22\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 24\u001B[0m \u001B[43mresult\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mloss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_idx \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;66;03m# 在每个 Epoch 的最后输出一下结果\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/hug-trans/lib/python3.8/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/hug-trans/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "pre = time.time()\n",
    "\n",
    "epoch = 30  # 循环学习 30 次\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)  # 定义优化器\n",
    "\n",
    "for i in range(epoch):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        result = model(data, labels=target)\n",
    "        total_loss += result['loss']\n",
    "\n",
    "        result['loss'].backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx == len(train_loader)-1:\n",
    "            # 在每个 Epoch 的最后输出一下结果\n",
    "            print('average loss:', total_loss/len(train_loader))\n",
    "\n",
    "print('训练时间：', time.time()-pre)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}